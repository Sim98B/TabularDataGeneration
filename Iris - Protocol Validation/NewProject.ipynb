{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cdba8c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T13:16:57.664728Z",
     "start_time": "2025-01-07T13:16:57.662378Z"
    }
   },
   "source": [
    "# Iris Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca0d7dd",
   "metadata": {},
   "source": [
    "# Index\n",
    "\n",
    "1. [Libraries](#Libraries)\n",
    "2. [Data Preparation](#Getting-Started)\n",
    "3. [Exploring Architectures](#GAN-vs-VAE)\n",
    "3. [Generating Syntethic Data](#Conditional-Generative-Adversarial-Network)\n",
    "4. [Syntethic VS Real](#Quality-assessment)\n",
    "5. [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f273192c",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed49d538",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T19:30:52.932087Z",
     "start_time": "2025-01-13T19:30:50.483344Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import skew, kurtosis, iqr, entropy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "import random\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd22832",
   "metadata": {},
   "source": [
    "Seed function for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "002f64ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T19:30:52.934985Z",
     "start_time": "2025-01-13T19:30:52.933356Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_seed(seed = 0):\n",
    "    \n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa4fc019",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T19:30:53.279479Z",
     "start_time": "2025-01-13T19:30:52.935718Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m project_path \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mpath:\n\u001b[1;32m      4\u001b[0m     sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(project_path)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/TabularDataGeneration/utils.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompare_results\u001b[39m(data1: \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mtensor, data2: torch\u001b[38;5;241m.\u001b[39mtensor):\n\u001b[1;32m     10\u001b[0m     mean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data1\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m data2\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     11\u001b[0m     std \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data1\u001b[38;5;241m.\u001b[39mstd(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m data2\u001b[38;5;241m.\u001b[39mstd(\u001b[38;5;241m0\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "project_path = os.path.abspath(\"..\")\n",
    "\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e4d327",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "The iris dataset will be used to validate the tabular data generation protocol, which despite its apparent simplicity may harbor pitfalls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb173314",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T19:30:53.284335Z",
     "start_time": "2025-01-13T19:30:53.284329Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = load_iris()['data'], load_iris()['target']\n",
    "features, species = load_iris()['feature_names'], load_iris()['target_names']\n",
    "\n",
    "real_iris = pd.DataFrame(X, columns = features)\n",
    "real_iris['target'] = y\n",
    "real_iris['target'] = real_iris['target'].map({i: species[i] for i in range(len(species))})\n",
    "real_iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a5f0ca",
   "metadata": {},
   "source": [
    "Let's deep dive into our real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba88074",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T19:30:53.284854Z",
     "start_time": "2025-01-13T19:30:53.284848Z"
    }
   },
   "outputs": [],
   "source": [
    "utils.describe_data(real_iris, 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9510ef4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T19:30:53.285510Z",
     "start_time": "2025-01-13T19:30:53.285505Z"
    }
   },
   "outputs": [],
   "source": [
    "utils.plot_data(real_iris, 'target')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800635c2",
   "metadata": {},
   "source": [
    "Throughout the notebook we will make comparisons between two datasets, one real and one synthetic; the following dataset, generated by adding normal noise to the real one, is used to introduce the comparison functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661edfd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T19:30:53.287085Z",
     "start_time": "2025-01-13T19:30:53.287076Z"
    }
   },
   "outputs": [],
   "source": [
    "df = real_iris.select_dtypes('number') + np.random.normal(0, 1, (150,4))\n",
    "df['target'] = real_iris['target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cddf260",
   "metadata": {},
   "source": [
    "Let's start with comparisons! \n",
    "\n",
    "First of all a simply comparison between descriptives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f551a0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T19:30:53.289368Z",
     "start_time": "2025-01-13T19:30:53.289359Z"
    }
   },
   "outputs": [],
   "source": [
    "utils.describe_data(real_iris, 'target', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4728bdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T19:30:53.290404Z",
     "start_time": "2025-01-13T19:30:53.290396Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "utils.plot_data(real_iris, 'target', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fda3301",
   "metadata": {},
   "source": [
    "Throughout the work, the goal will be to minimize the differences, numerical and graphical, between the actual and synthetic data. Two different architectures will be used to achieve this goal: the Variational Auto Encoder **(VAE)** and the Generative Adversarial Network **(GAN)**, and the one that will show the best performance for the same task complexity and resources will be selected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a5410d",
   "metadata": {},
   "source": [
    "## GAN vs VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc29a884",
   "metadata": {},
   "source": [
    "Both valid, the two approaches show different challenges and advantages:\n",
    "\n",
    "1. **Variational Auto Encoder**:\n",
    "\n",
    "Pros:\n",
    "- Easy to train\n",
    "- We can look inside the neaural network \"Black Box\"\n",
    "\n",
    "Cons:\n",
    "\n",
    "- Less coverage of variability\n",
    "- Assumption of data normality\n",
    "\n",
    "2. **Generative Adversarial Network**:\n",
    "\n",
    "Pros:\n",
    "- More realistic generated data\n",
    "- Flexibility with respect to actual data distributions\n",
    "\n",
    "Cons:\n",
    "- Hard to train (model collapse, lot of resources, lot of data)\n",
    "- Lower interpretability\n",
    "\n",
    "The performance of the two architectures will be analyzed using them in as simple a version as possible. The next step will then be to prepare the data for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b8dd01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T19:30:53.291542Z",
     "start_time": "2025-01-13T19:30:53.291534Z"
    }
   },
   "outputs": [],
   "source": [
    "std_scl = StandardScaler()\n",
    "X_scld = std_scl.fit_transform(X)\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output = False)\n",
    "y_ohe = ohe.fit_transform(y.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21518d2a",
   "metadata": {},
   "source": [
    "Preparing Torch Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4e4d69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T19:30:53.292609Z",
     "start_time": "2025-01-13T19:30:53.292602Z"
    }
   },
   "outputs": [],
   "source": [
    "class IrisDataset(Dataset):\n",
    "    def __init__(self, data, target):\n",
    "        self.data = torch.tensor(data, dtype = torch.float32)\n",
    "        self.label = torch.tensor(target, dtype = torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.label[idx]\n",
    "    \n",
    "real_vae_dataset = IrisDataset(X_scld, y_ohe)\n",
    "real_vae_dataloader = DataLoader(real_vae_dataset, batch_size = 32, shuffle = True)\n",
    "\n",
    "real_gan_dataset = IrisDataset(X_scld, y)\n",
    "real_gan_dataloader = DataLoader(real_gan_dataset, batch_size = 32, shuffle = True)\n",
    "\n",
    "for dataloader in [real_vae_dataloader, real_gan_dataloader]:\n",
    "    for batch in dataloader:\n",
    "        print(f'Data shape: {batch[0].shape}, labels shape: {batch[1].shape}')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9164a8ad",
   "metadata": {},
   "source": [
    "Let's build baseline models, starting with the Conditional VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5231add8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T19:30:53.293554Z",
     "start_time": "2025-01-13T19:30:53.293548Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConditionalVAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, condition_dim):\n",
    "        super(ConditionalVAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim + condition_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.fc_mu = nn.Linear(16, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(16, latent_dim)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim + condition_dim, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, input_dim),\n",
    "            nn.Tanh()  # Output compreso tra 0 e 1\n",
    "        )\n",
    "        \n",
    "    def encode(self, x, c):\n",
    "        x_cond = torch.cat([x, c], dim=1)\n",
    "        h = self.encoder(x_cond)\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z, c):\n",
    "        z_cond = torch.cat([z, c], dim=1)\n",
    "        return self.decoder(z_cond)\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        mu, logvar = self.encode(x, c)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon_x = self.decode(z, c)\n",
    "        return recon_x, mu, logvar\n",
    "    \n",
    "    \n",
    "vae = ConditionalVAE(input_dim = 4, latent_dim = 2, condition_dim = 3)\n",
    "\n",
    "for batch in real_vae_dataloader:\n",
    "    batch = batch\n",
    "    break\n",
    "    \n",
    "vae_out = vae(batch[0], batch[1])\n",
    "for out in vae_out:\n",
    "    print(f'Shape: {out.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dfa741",
   "metadata": {},
   "source": [
    "Now let's build the GANs net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57bc53f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T19:30:53.294787Z",
     "start_time": "2025-01-13T19:30:53.294777Z"
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim + num_classes, 32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(16, 4)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, labels):\n",
    "        label_embeddings = self.label_emb(labels)\n",
    "        x = torch.cat([x, label_embeddings], dim = 1)\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "            \n",
    "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim + num_classes, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, labels):\n",
    "        label_embeddings = self.label_emb(labels)\n",
    "        x = torch.cat([x, label_embeddings], dim = 1)\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "gen = Generator(input_dim = 2, num_classes = 3)\n",
    "disc = Discriminator(input_dim = 4, num_classes = 3)\n",
    "\n",
    "for batch in real_gan_dataloader:\n",
    "    batch = batch\n",
    "    break\n",
    "    \n",
    "print(f'Generator output shape: {gen(torch.randn(32, 2), batch[1]).shape}')\n",
    "print(f'Discriminator output shape: {disc(batch[0], batch[1]).shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ed2b6c",
   "metadata": {},
   "source": [
    "Let's check models' size in parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d2255f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T19:30:53.296379Z",
     "start_time": "2025-01-13T19:30:53.296374Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'VAE has {sum(p.numel() for p in vae.parameters())} parameters')\n",
    "print(f'Gen has {sum(p.numel() for p in gen.parameters())} parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4711cbfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T19:30:53.297942Z",
     "start_time": "2025-01-13T19:30:53.297926Z"
    }
   },
   "outputs": [],
   "source": [
    "utils.compare_results(batch[0], batch[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
